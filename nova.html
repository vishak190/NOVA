<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>NOVA ‚Äì AI Walking Assistant</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />

  <!-- TensorFlow.js + COCO-SSD for object detection -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.21.0/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>

  <!-- Tesseract.js for OCR -->
  <script src="https://cdn.jsdelivr.net/npm/tesseract.js@5.0.4/dist/tesseract.min.js"></script>

  <style>
    :root {
      --bg: #000000;
      --accent: #22c55e;
      --accent-soft: rgba(34, 197, 94, 0.16);
      --text-main: #f9fafb;
      --text-subtle: #9ca3af;
      --danger: #f97373;
      --card-bg: rgba(15, 23, 42, 0.96);
    }

    * {
      box-sizing: border-box;
      margin: 0;
      padding: 0;
      font-family: system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI",
        sans-serif;
    }

    body {
      background: #000;
      color: var(--text-main);
      width: 100vw;
      height: 100vh;
      overflow: hidden;
      margin: 0;
      padding: 0;
      display: flex;
      justify-content: center;
      align-items: stretch;
    }

    .app {
      width: 100vw;
      height: 100vh;
      max-width: 100vw;
      margin: 0;
      display: flex;
      flex-direction: column;
      padding: 0;
      gap: 0;
    }

    header {
      display: flex;
      align-items: center;
      justify-content: space-between;
      padding: 6px 10px;
      border-radius: 0;
      background: rgba(15, 23, 42, 0.9);
      box-shadow: 0 6px 16px rgba(0, 0, 0, 0.6);
      backdrop-filter: blur(16px);
      z-index: 2;
    }

    .logo-text {
      display: flex;
      align-items: center;
      gap: 8px;
      font-weight: 700;
      letter-spacing: 0.12em;
      text-transform: uppercase;
    }

    .logo-circle {
      width: 26px;
      height: 26px;
      border-radius: 999px;
      border: 2px solid var(--accent);
      display: flex;
      align-items: center;
      justify-content: center;
      font-size: 14px;
    }

    .badge {
      font-size: 11px;
      padding: 3px 8px;
      border-radius: 999px;
      background: rgba(34, 197, 94, 0.12);
      color: var(--accent);
      text-transform: uppercase;
      letter-spacing: 0.08em;
    }

    .main-card {
      flex: 1;
      width: 100vw;
      height: 100%;
      position: relative;
      border-radius: 0;
      overflow: hidden;
      background: #000;
      border: none;
      display: flex;
      flex-direction: column; /* mobile: stacked */
    }

    .video-wrapper {
      position: relative;
      flex: 1;
      width: 100%;
      height: 100%;
      background: #000;
    }

    video,
    canvas#overlay {
      position: absolute;
      inset: 0;
      width: 100%;
      height: 100%;
      object-fit: cover;
    }

    .video-overlay-fade {
      position: absolute;
      inset: 0;
      background: radial-gradient(circle at top, transparent 40%, #020617 100%);
      pointer-events: none;
    }

    .status-bar {
      position: absolute;
      top: 10px;
      left: 10px;
      right: 10px;
      padding: 6px 9px;
      border-radius: 999px;
      background: rgba(15, 23, 42, 0.9);
      display: flex;
      align-items: center;
      justify-content: space-between;
      gap: 8px;
      font-size: 11px;
      color: var(--text-subtle);
      z-index: 2;
    }

    .status-bar strong {
      color: var(--text-main);
    }

    .status-dot {
      width: 8px;
      height: 8px;
      border-radius: 999px;
      background: var(--danger);
      box-shadow: 0 0 12px rgba(248, 113, 113, 0.8);
    }

    .status-dot.on {
      background: var(--accent);
      box-shadow: 0 0 12px rgba(34, 197, 94, 0.9);
    }

    /* ---------- CENTER OBJECT CARD ---------- */
    .object-card {
      position: absolute;
      left: 50%;
      top: 52%;
      transform: translate(-50%, -50%);
      width: 82%;
      max-width: 360px;
      background: var(--card-bg);
      border-radius: 22px;
      box-shadow: 0 20px 45px rgba(0, 0, 0, 0.6);
      padding: 10px 12px;
      display: flex;
      flex-direction: column;
      gap: 8px;
      border: 1px solid rgba(148, 163, 184, 0.4);
      z-index: 1;
    }

    .object-card-tabs {
      display: inline-flex;
      align-items: center;
      background: rgba(15, 23, 42, 0.95);
      border-radius: 999px;
      padding: 2px;
      gap: 2px;
      font-size: 11px;
    }

    .object-card-tab {
      padding: 4px 10px;
      border-radius: 999px;
      border: none;
      font-size: 11px;
      cursor: default;
      background: transparent;
      color: var(--text-subtle);
      text-transform: none;
    }

    .object-card-tab.active {
      background: var(--accent-soft);
      color: var(--accent);
      font-weight: 600;
    }

    .object-card-title {
      font-size: 11px;
      color: var(--text-subtle);
      text-transform: uppercase;
      letter-spacing: 0.12em;
    }

    .object-card-main {
      display: flex;
      align-items: center;
      gap: 10px;
    }

    .object-card-avatar {
      width: 44px;
      height: 44px;
      border-radius: 16px;
      background: radial-gradient(circle at 30% 20%, #22c55e, #0b1120);
      display: flex;
      align-items: center;
      justify-content: center;
      font-size: 20px;
    }

    .object-card-text {
      flex: 1;
      display: flex;
      flex-direction: column;
      gap: 2px;
    }

    .object-name {
      font-size: 15px;
      font-weight: 600;
    }

    .object-meta {
      font-size: 12px;
      color: var(--text-subtle);
      line-height: 1.4;
    }

    .object-meta strong {
      color: var(--text-main);
    }

    .object-card-footer {
      margin-top: 2px;
      display: flex;
      align-items: center;
      justify-content: space-between;
      font-size: 11px;
      color: var(--text-subtle);
      gap: 8px;
      flex-wrap: wrap;
    }

    .chip {
      padding: 4px 8px;
      border-radius: 999px;
      background: rgba(148, 163, 184, 0.16);
    }

    /* ---------- BOTTOM / SIDE SHEET ---------- */
    .bottom-panel {
      padding: 10px 12px 8px;
      display: flex;
      flex-direction: column;
      gap: 8px;
      background: rgba(15, 23, 42, 0.96);
      border-top: 1px solid rgba(148, 163, 184, 0.35);
      backdrop-filter: blur(22px);
    }

    .scene-header-row {
      display: flex;
      align-items: center;
      justify-content: space-between;
      gap: 8px;
      font-size: 12px;
    }

    .scene-count {
      font-weight: 600;
    }

    .lang-indicator {
      font-size: 11px;
      padding: 3px 8px;
      border-radius: 999px;
      border: 1px solid rgba(148, 163, 184, 0.5);
      color: var(--text-subtle);
    }

    .scene-main {
      font-size: 12px;
      color: var(--text-main);
    }

    .scene-list {
      font-size: 11px;
      color: var(--text-subtle);
      max-height: 76px;
      overflow: hidden;
    }

    .scene-list-line + .scene-list-line {
      margin-top: 2px;
    }

    .hint {
      font-size: 11px;
      color: var(--text-subtle);
    }

    .log {
      display: none;
      font-size: 10px;
    }

    /* NEW: voice command display */
    .voice-command-display {
      font-size: 11px;
      color: var(--text-subtle);
      padding: 4px 6px;
      border-radius: 8px;
      background: rgba(15, 23, 42, 0.9);
      border: 1px solid rgba(148, 163, 184, 0.35);
      margin-top: 2px;
      max-height: 38px;
      overflow: hidden;
      text-overflow: ellipsis;
      white-space: nowrap;
    }

    @media (max-height: 640px) {
      header {
        padding: 4px 8px;
      }
      .object-card {
        top: 50%;
      }
      .bottom-panel {
        padding: 8px 10px 6px;
      }
    }

    /* -----------------------------
       DESKTOP / LARGE SCREEN LAYOUT
       ----------------------------- */
    @media (min-width: 900px) {
      body {
        align-items: stretch;
      }

      .app {
        max-width: 100vw;
        min-height: 100vh;
        padding: 0;
        gap: 0;
      }

      .main-card {
        flex: 1;
        flex-direction: row; /* camera left, panel right */
      }

      .video-wrapper {
        flex: 3;
        min-height: 480px;
      }

      .bottom-panel {
        flex: 2;
        border-top: none;
        border-left: 1px solid rgba(148, 163, 184, 0.35);
        padding: 14px 16px;
        max-width: 380px;
      }

      .scene-list {
        max-height: 180px;
        overflow-y: auto;
      }

      .object-card {
        width: 70%;
        max-width: 420px;
      }
    }

    /* Optional: hide header in landscape for pure camera feel */
    @media (orientation: landscape) {
      header {
        display: none;
      }
    }
  </style>
</head>

<body>
  <div class="app">
    <header>
      <div class="logo-text" aria-label="NOVA Assistant">
        <div class="logo-circle">N</div>
        <div>N.O.V.A</div>
      </div>
      <div class="badge" id="speech-status">Voice: ON</div>
    </header>

    <main class="main-card" aria-live="polite">
      <div class="video-wrapper">
        <video id="camera" autoplay playsinline muted></video>
        <canvas id="overlay"></canvas>
        <div class="video-overlay-fade"></div>

        <div class="status-bar">
          <div style="display:flex; align-items:center; gap:6px;">
            <div id="camera-dot" class="status-dot"></div>
            <span id="mode-label"><strong>Object</strong> mode</span>
          </div>
          <div id="distance-status">Waiting for camera‚Ä¶</div>
        </div>

        <!-- Center floating object info card -->
        <section class="object-card" aria-live="polite">
          <div class="object-card-tabs">
            <button class="object-card-tab active" type="button">Object info</button>
            <button class="object-card-tab" type="button">Scene</button>
          </div>

          <div class="object-card-title" id="primary-object-title">
            Nearest object
          </div>

          <div class="object-card-main">
            <div class="object-card-avatar" id="primary-object-icon">
              üß≠
            </div>
            <div class="object-card-text">
              <div class="object-name" id="primary-object-name">
                Looking for objects‚Ä¶
              </div>
              <div class="object-meta" id="primary-object-meta">
                Move the phone slowly in front of you.
              </div>
            </div>
          </div>

          <div class="object-card-footer">
            <div class="chip" id="primary-object-chip">
              No objects detected yet
            </div>
            <div style="font-size:11px;">
              Voice only ‚Äî say: <strong>‚Äúobject mode‚Äù</strong>,
              <strong>‚Äúbook mode‚Äù</strong>, <strong>‚Äúread‚Äù</strong>
            </div>
          </div>
        </section>
      </div>

      <!-- Bottom / side panel for scene details -->
      <section class="bottom-panel">
        <div class="scene-header-row">
          <div class="scene-count" id="scene-count-label">No objects detected</div>
          <div class="lang-indicator" id="lang-indicator">
            Commands: Malayalam
          </div>
        </div>

        <div class="scene-main" id="primary-details">
          When NOVA finds something, you will hear the name, distance in meters,
          position, size, and how many similar objects are there.
        </div>

        <div class="scene-list" id="scene-list"></div>

        <!-- NEW: show last voice command -->
        <div class="voice-command-display" id="voice-command-display">
          Waiting for voice command‚Ä¶ Tap once and speak.
        </div>

        <div class="hint">
          Change language: say <strong>‚ÄúMalayalam mode‚Äù</strong> or
          <strong>‚ÄúEnglish mode‚Äù</strong>. Mute with <strong>‚Äúmute‚Äù</strong>.
        </div>

        <div class="log" id="log"></div>
      </section>
    </main>
  </div>

  <script>
    // ------------------------------
    // GLOBAL STATE
    // ------------------------------
    let video = null;
    let canvas = null;
    let ctx = null;

    let objectModel = null; // COCO-SSD model
    let isCameraOn = false;
    let isDetecting = false;

    let currentMode = "object"; // "object" or "book"
    let speechEnabled = true;
    let lastSpokenSummary = "";
    let lastSpokenTime = 0;

    let recognition = null; // SpeechRecognition instance
    let recognitionLang = "ml-IN"; // command language (Malayalam or English)
    let isRecognitionActive = false; // NEW: track if recognition is running

    // Track last voice command for display + 4 sec check
    let lastVoiceCommand = "";
    let lastVoiceTime = 0;

    // object memory (for first-time description)
    let knownObjectSignatures = new Set();

    const MIN_CONFIDENCE = 0.6;

    // üîÑ Voice environment updates: every 10 seconds
    const ENV_SPEAK_INTERVAL_MS = 10000;
    const PROX_ALERT_INTERVAL_MS = 5000;

    const DETECTION_MEMORY_MS = 20000;
    let detectionHistory = [];
    let lastProximityAlertTime = 0;

    const SPEECH_LANG = "en-IN";

    // Interval for mic check and voice display (4 seconds)
    const VOICE_CHECK_INTERVAL_MS = 4000;

    // ------------------------------
    // FULLSCREEN + AUTO LANDSCAPE
    // ------------------------------
    async function forceLandscape() {
      try {
        if (screen.orientation && screen.orientation.lock) {
          await screen.orientation.lock("landscape");
          console.log("Landscape locked");
        }
      } catch (e) {
        console.warn("Orientation lock not supported:", e);
      }
    }

    async function requestFullScreen() {
      const el = document.documentElement;
      try {
        if (el.requestFullscreen) {
          await el.requestFullscreen();
        } else if (el.webkitRequestFullscreen) {
          await el.webkitRequestFullscreen();
        }
      } catch (e) {
        console.warn("Fullscreen request failed:", e);
      }
    }

    let fullscreenRequested = false;
    document.addEventListener("click", async () => {
      // First-time fullscreen/orientation
      if (!fullscreenRequested) {
        fullscreenRequested = true;
        await requestFullScreen();
        await forceLandscape();
      }

      // Start speech recognition on first user tap
      if (recognition && !isRecognitionActive) {
        try {
          recognition.start();
          console.log("Trying to start recognition from user click");
          setLog("Voice commands active. Say object mode, book mode, or read.");
          const vDisplay = document.getElementById("voice-command-display");
          vDisplay.textContent = "Listening‚Ä¶ Say a command like 'object mode' or 'read'.";
        } catch (e) {
          console.warn("Failed to start recognition on click:", e);
        }
      }
    });

    // ------------------------------
    // HELPERS
    // ------------------------------
    function setLog(message) {
      const log = document.getElementById("log");
      log.innerHTML = message;
    }

    function speak(text, options = {}) {
      if (!speechEnabled) return;
      if (!("speechSynthesis" in window)) {
        console.warn("SpeechSynthesis not supported");
        return;
      }
      const utterance = new SpeechSynthesisUtterance(text);
      utterance.rate = options.rate || 1.0;
      utterance.pitch = options.pitch || 1.0;
      utterance.lang = options.lang || SPEECH_LANG;
      window.speechSynthesis.cancel();
      window.speechSynthesis.speak(utterance);
    }

    function vibrate(pattern) {
      if (navigator.vibrate) {
        navigator.vibrate(pattern);
      }
    }

    function updateModeUI() {
      const modeLabel = document.getElementById("mode-label");
      if (currentMode === "object") {
        modeLabel.innerHTML = "<strong>Object</strong> mode";
      } else {
        modeLabel.innerHTML = "<strong>Book</strong> mode";
      }
    }

    function setCameraStatus(on) {
      const dot = document.getElementById("camera-dot");
      const distanceStatus = document.getElementById("distance-status");
      if (on) {
        dot.classList.add("on");
        distanceStatus.textContent = "Camera active. Scanning‚Ä¶";
      } else {
        dot.classList.remove("on");
        distanceStatus.textContent = "Camera off.";
      }
    }

    function setSpeechBadge() {
      const badge = document.getElementById("speech-status");
      if (speechEnabled) {
        badge.textContent = "Voice: ON";
        badge.style.backgroundColor = "rgba(34, 197, 94, 0.12)";
        badge.style.color = "#22c55e";
      } else {
        badge.textContent = "Voice: OFF";
        badge.style.backgroundColor = "rgba(148, 163, 184, 0.25)";
        badge.style.color = "#e5e7eb";
      }
    }

    function setRecognitionLanguage(langCode) {
      recognitionLang = langCode;
      if (recognition) {
        recognition.lang = recognitionLang;
        try {
          recognition.stop();
        } catch (e) {}
        // will restart via onend OR user tap
      }
      const langLabel = langCode === "ml-IN" ? "Malayalam" : "English";
      document.getElementById("lang-indicator").textContent =
        "Commands: " + langLabel;
      setLog(`Command language: ${langLabel}.`);
      speak(`${langLabel} command mode.`, { rate: 1.0 });
    }

    function formatMeters(meters) {
      const rounded = Math.round(meters * 10) / 10;
      return rounded.toFixed(1); // 1 decimal place
    }

    // ------------------------------
    // CAMERA
    // ------------------------------
    async function startCamera() {
      try {
        video = document.getElementById("camera");
        canvas = document.getElementById("overlay");
        ctx = canvas.getContext("2d");

        const stream = await navigator.mediaDevices.getUserMedia({
          video: { facingMode: { ideal: "environment" } },
          audio: false,
        });

        video.srcObject = stream;

        await new Promise((resolve) => {
          video.onloadedmetadata = () => {
            video.play();
            resolve();
          };
        });

        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;

        isCameraOn = true;
        setCameraStatus(true);

        if (objectModel && !isDetecting && currentMode === "object") {
          isDetecting = true;
          detectLoop();
        }

        setLog("<strong>Camera on.</strong> Voice control is ready after you tap once.");
      } catch (err) {
        console.error(err);
        setLog(
          "Could not access camera. Please allow camera permission and run this app from <strong>http://localhost</strong> or <strong>HTTPS</strong>."
        );
        speak("I cannot access the camera. Please check permissions.");
      }
    }

    function stopCamera() {
      if (!video || !video.srcObject) return;
      let tracks = video.srcObject.getTracks();
      tracks.forEach((t) => t.stop());
      video.srcObject = null;
      isCameraOn = false;
      isDetecting = false;
      setCameraStatus(false);
      ctx && ctx.clearRect(0, 0, canvas.width, canvas.height);
      setLog("Camera stopped.");
    }

    // ------------------------------
    // DISTANCE + DIRECTION + SIZE LABELS
    // ------------------------------
    function estimateDistanceMeters(bbox) {
      const boxHeight = bbox[3];
      const relHeight = boxHeight / canvas.height;

      let positionLabel = "";
      let meters = 0;

      if (relHeight > 0.6) {
        positionLabel = "very close";
        meters = 0.5;
      } else if (relHeight > 0.4) {
        positionLabel = "close";
        meters = 1.0;
      } else if (relHeight > 0.25) {
        positionLabel = "medium distance";
        meters = 2.0;
      } else if (relHeight > 0.15) {
        positionLabel = "far";
        meters = 3.0;
      } else {
        positionLabel = "very far";
        meters = 4.0;
      }

      return { positionLabel, meters };
    }

    function getDirection(bbox) {
      const [x, , w] = bbox;
      const centerX = x + w / 2;
      const third = canvas.width / 3;

      if (centerX < third) return "left";
      if (centerX > 2 * third) return "right";
      return "center";
    }

    function getSizeLabel(bbox) {
      const [, , w, h] = bbox;
      const area = w * h;
      const frameArea = canvas.width * canvas.height;
      const ratio = area / frameArea;

      if (ratio > 0.4) return "very large";
      if (ratio > 0.25) return "large";
      if (ratio > 0.12) return "medium";
      if (ratio > 0.04) return "small";
      return "very small";
    }

    // ------------------------------
    // DRAWING + MEMORY
    // ------------------------------
    function drawPredictions(predictions) {
      if (!ctx) return;

      ctx.clearRect(0, 0, canvas.width, canvas.height);

      predictions.forEach((p) => {
        const [x, y, w, h] = p.bbox;
        const { meters } = estimateDistanceMeters(p.bbox);
        const metersLabel = formatMeters(meters);

        ctx.lineWidth = 3;
        ctx.strokeStyle = "rgba(34, 197, 94, 0.9)";
        ctx.fillStyle = "rgba(15, 23, 42, 0.8)";
        ctx.beginPath();
        if (typeof ctx.roundRect === "function") {
          ctx.roundRect(x, y, w, h, 10);
        } else {
          ctx.rect(x, y, w, h);
        }
        ctx.stroke();

        const label = `${p.class} ¬∑ ${metersLabel} m`;
        const textX = x + 6;
        const boxY = y - 22 < 0 ? y + 4 : y - 22;
        const textWidth = ctx.measureText(label).width + 14;

        ctx.fillRect(x, boxY, textWidth, 22);
        ctx.fillStyle = "#e5e7eb";
        ctx.font = "13px system-ui";
        ctx.fillText(label, textX, boxY + 15);
      });
    }

    function updateDetectionMemory(objects) {
      const now = Date.now();
      detectionHistory.push({ time: now, objects });

      const cutoff = now - DETECTION_MEMORY_MS;
      detectionHistory = detectionHistory.filter((item) => item.time >= cutoff);
    }

    function getObjectSignature(obj) {
      const bucket = Math.round(obj.meters * 2) / 2; // 0.5 m groups
      return `${obj.name}|${obj.dir}|${bucket}`;
    }

    // ------------------------------
    // UPDATE UI DETAILS (CARD + BOTTOM SHEET)
    // ------------------------------
    function updateObjectDetailsUI(objects) {
      const sceneCountLabel = document.getElementById("scene-count-label");
      const primaryDetails = document.getElementById("primary-details");
      const sceneList = document.getElementById("scene-list");

      const primaryNameEl = document.getElementById("primary-object-name");
      const primaryMetaEl = document.getElementById("primary-object-meta");
      const primaryChipEl = document.getElementById("primary-object-chip");
      const primaryTitleEl = document.getElementById("primary-object-title");
      const primaryIconEl = document.getElementById("primary-object-icon");

      if (!objects.length) {
        sceneCountLabel.textContent = "No objects detected";
        primaryNameEl.textContent = "No objects in front of you";
        primaryMetaEl.textContent =
          "Move the phone slowly. I will tell you when I find something.";
        primaryChipEl.textContent = "Waiting for objects‚Ä¶";
        primaryTitleEl.textContent = "Nearest object";
        primaryIconEl.textContent = "üß≠";
        primaryDetails.textContent =
          "No obstacles detected right now. Keep walking carefully.";
        sceneList.innerHTML = "";
        return;
      }

      const count = objects.length;
      sceneCountLabel.textContent =
        count + (count === 1 ? " object detected" : " objects detected");

      const sorted = objects.slice().sort((a, b) => a.meters - b.meters);
      const nearest = sorted[0];
      const metersLabel = formatMeters(nearest.meters);
      const sameCount = objects.filter((o) => o.name === nearest.name).length;

      let sideTextUI = "center";
      if (nearest.dir === "left") sideTextUI = "left side";
      if (nearest.dir === "right") sideTextUI = "right side";

      primaryTitleEl.textContent = "Nearest object";
      primaryNameEl.textContent = nearest.name;
      primaryMetaEl.innerHTML =
        `<strong>${metersLabel} m</strong> ¬∑ ${nearest.positionLabel} ¬∑ ${nearest.sizeLabel} ¬∑ ` +
        `${sameCount} in scene ¬∑ ${sideTextUI}`;
      primaryChipEl.textContent =
        nearest.dir === "center"
          ? "Straight ahead"
          : nearest.dir === "left"
          ? "On your left"
          : "On your right";
      primaryIconEl.textContent = nearest.name === "person" ? "üë§" : "‚¨õ";

      primaryDetails.textContent =
        `Nearest: ${nearest.name}, ${metersLabel} meters, ` +
        `${nearest.positionLabel}, ${nearest.sizeLabel}, on your ${sideTextUI}. ` +
        `Total ${sameCount} ${nearest.name}${sameCount > 1 ? "s" : ""} in this view.`;

      sceneList.innerHTML = "";
      sorted.forEach((o, i) => {
        const line = document.createElement("div");
        line.className = "scene-list-line";
        const metersText = formatMeters(o.meters);
        let sideWord = "center";
        if (o.dir === "left") sideWord = "left";
        if (o.dir === "right") sideWord = "right";
        line.textContent =
          `${i + 1}. ${o.name} ‚Äî ${metersText} m, ` +
          `${o.positionLabel}, ${o.sizeLabel}, ${sideWord}.`;
        sceneList.appendChild(line);
      });
    }

    // ------------------------------
    // SPEAKING / PROXIMITY
    // ------------------------------
    function describeObjectsDetailed(objects, isNewOnly) {
      if (!objects.length) return;

      const count = objects.length;
      const intro = isNewOnly
        ? count === 1
          ? "New object detected."
          : `${count} new objects detected.`
        : `I see ${count} objects in front of you.`;

      const details = objects
        .map((o, idx) => {
          const metersText = formatMeters(o.meters);
          let sideText = "in the center";
          if (o.dir === "left") sideText = "on your left";
          if (o.dir === "right") sideText = "on your right";
          return `Object ${idx + 1}: ${o.name}, ${o.positionLabel}, ${o.sizeLabel}, ${sideText}, about ${metersText} meters.`;
        })
        .join(" ");

      const finalText = intro + " " + details;
      speak(finalText, { rate: 0.9 });
    }

    function maybeSpeakEnvironment(objects) {
      if (!speechEnabled) return;
      if (!objects.length) {
        document.getElementById("distance-status").textContent =
          "No obstacle detected.";
        return;
      }

      const now = Date.now();
      const newObjects = [];
      objects.forEach((o) => {
        const sig = getObjectSignature(o);
        if (!knownObjectSignatures.has(sig)) {
          knownObjectSignatures.add(sig);
          newObjects.push(o);
        }
      });

      if (
        knownObjectSignatures.size &&
        knownObjectSignatures.size === objects.length &&
        newObjects.length === objects.length &&
        lastSpokenTime === 0
      ) {
        describeObjectsDetailed(objects, false);
        lastSpokenTime = now;
        lastSpokenSummary = "first scene";
        const nearest = objects.slice().sort((a, b) => a.meters - b.meters)[0];
        const metersText = formatMeters(nearest.meters);
        document.getElementById("distance-status").textContent =
          `Nearest: ${nearest.name} ~${metersText} m, ${nearest.dir}`;
        return;
      }

      if (newObjects.length && now - lastSpokenTime > ENV_SPEAK_INTERVAL_MS) {
        describeObjectsDetailed(newObjects, true);
        lastSpokenTime = now;
        lastSpokenSummary = "new objects";
        const nearest = objects.slice().sort((a, b) => a.meters - b.meters)[0];
        const metersText = formatMeters(nearest.meters);
        document.getElementById("distance-status").textContent =
          `Nearest: ${nearest.name} ~${metersText} m, ${nearest.dir}`;
        return;
      }

      if (now - lastSpokenTime < ENV_SPEAK_INTERVAL_MS) return;

      const count = objects.length;
      const sorted = objects.slice().sort((a, b) => a.meters - b.meters);
      const top = sorted.slice(0, 3);

      const phraseParts = top.map((o) => {
        let side = "in the center";
        if (o.dir === "left") side = "on your left";
        if (o.dir === "right") side = "on your right";
        const metersText = formatMeters(o.meters);
        return `${o.name} ${side}, ${metersText} meters`;
      });

      const sentence =
        `${count} object` +
        (count > 1 ? "s" : "") +
        ` ahead: ` +
        phraseParts.join(", ") +
        ".";

      if (sentence === lastSpokenSummary) return;

      speak(sentence, { rate: 0.95 });
      lastSpokenSummary = sentence;
      lastSpokenTime = now;

      const nearest = sorted[0];
      const nearestMetersText = formatMeters(nearest.meters);
      const distanceStatus = document.getElementById("distance-status");
      distanceStatus.textContent =
        `Nearest: ${nearest.name} ~${nearestMetersText} m, ${nearest.dir}`;

      // Haptic alert based on distance (no speech here, only vibration)
      if (nearest.meters <= 0.8) {
        vibrate([300, 150, 300, 150, 300]);
      } else if (nearest.meters <= 1.5) {
        vibrate([200, 120, 200]);
      }
    }

    function analyzeProximity(objects) {
      const now = Date.now();
      if (now - lastProximityAlertTime < PROX_ALERT_INTERVAL_MS) return;

      const persons = objects.filter((o) => o.name === "person");
      const obstacles = objects.filter((o) => o.name !== "person");

      if (!persons.length || !obstacles.length) return;

      let closestPair = null;

      persons.forEach((p) => {
        obstacles.forEach((o) => {
          const depthDiff = Math.abs(p.meters - o.meters);
          const dirSame =
            p.dir === o.dir || p.dir === "center" || o.dir === "center";

          if (depthDiff <= 1.2 && dirSame) {
            const score = depthDiff;
            if (!closestPair || score < closestPair.score) {
              closestPair = { p, o, score };
            }
          }
        });
      });

      if (!closestPair) return;

      const recentPast = detectionHistory.findLast
        ? detectionHistory.findLast(
            (d) => now - d.time > 2000 && now - d.time < 5000
          )
        : (() => {
            for (let i = detectionHistory.length - 1; i >= 0; i--) {
              const d = detectionHistory[i];
              if (now - d.time > 2000 && now - d.time < 5000) return d;
            }
            return null;
          })();

      if (recentPast) {
        const prevP = recentPast.objects.find(
          (o) => o.name === "person" && o.dir === closestPair.p.dir
        );
        const prevO = recentPast.objects.find(
          (o) => o.name === closestPair.o.name && o.dir === closestPair.o.dir
        );
        if (prevP && prevO) {
          const prevGap = Math.abs(prevP.meters - prevO.meters);
          const nowGap = Math.abs(closestPair.p.meters - closestPair.o.meters);
          if (nowGap > prevGap + 0.3) {
            return;
          }
        }
      }

      lastProximityAlertTime = now;
      const gapMeters = Math.max(
        0.3,
        Math.abs(closestPair.p.meters - closestPair.o.meters)
      );
      const gapMetersText = formatMeters(gapMeters);

      // HAPTIC-ONLY OBSTACLE ALERT (no voice)
      vibrate([400, 150, 400, 150, 400]);
      document.getElementById("distance-status").textContent =
        `Obstacle alert: gap ~${gapMetersText} m.`;
    }

    // ------------------------------
    // MAIN DETECTION LOOP
    // ------------------------------
    async function detectLoop() {
      if (!isDetecting || !objectModel || !isCameraOn) return;

      try {
        const predictions = await objectModel.detect(video);
        const filtered = predictions.filter((p) => p.score >= MIN_CONFIDENCE);

        drawPredictions(filtered);

        if (currentMode === "object") {
          if (filtered.length) {
            const objects = filtered.map((p) => {
              const { positionLabel, meters } = estimateDistanceMeters(p.bbox);
              const dir = getDirection(p.bbox);
              const sizeLabel = getSizeLabel(p.bbox);
              return { name: p.class, meters, dir, positionLabel, sizeLabel };
            });

            updateDetectionMemory(objects);
            updateObjectDetailsUI(objects);
            maybeSpeakEnvironment(objects);
            analyzeProximity(objects);
          } else {
            updateObjectDetailsUI([]);
            document.getElementById("distance-status").textContent =
              "No obstacle detected.";
          }
        }
      } catch (err) {
        console.error(err);
      } finally {
        requestAnimationFrame(detectLoop);
      }
    }

    // ------------------------------
    // BOOK READING (OCR)
    // ------------------------------
    async function readCurrentFrameText() {
      if (!isCameraOn || !video || !canvas) {
        setLog("Camera must be on to read text.");
        speak("Please turn on the camera first.", { rate: 1.0 });
        return;
      }

      setLog("Capturing frame and scanning for text‚Ä¶");
      speak("Scanning text. Please hold still.", { rate: 0.95 });

      isDetecting = false;
      ctx && ctx.clearRect(0, 0, canvas.width, canvas.height);

      try {
        const tempCanvas = document.createElement("canvas");
        tempCanvas.width = video.videoWidth;
        tempCanvas.height = video.videoHeight;
        const tctx = tempCanvas.getContext("2d");
        tctx.drawImage(video, 0, 0, tempCanvas.width, tempCanvas.height);

        const dataUrl = tempCanvas.toDataURL("image/png");

        const result = await Tesseract.recognize(dataUrl, "eng", {
          logger: (m) => console.log(m),
        });

        const text = (result.data.text || "").trim();

        if (text.length > 0) {
          setLog(`<strong>Reading:</strong> ${text}`);
          speak("Reading text.", { rate: 1.0 });
          speak(text, { rate: 0.9 });
        } else {
          setLog(
            "No clear text detected. Try again with closer, brighter image."
          );
          speak(
            "I could not see any clear text. Please move closer or adjust the lighting.",
            { rate: 1.0 }
          );
        }
      } catch (err) {
        console.error(err);
        setLog("Error reading text. See console for details.");
        speak("Something went wrong while reading the text.", { rate: 1.0 });
      } finally {
        if (currentMode === "object" && objectModel && isCameraOn) {
          isDetecting = true;
          detectLoop();
        }
      }
    }

    // ------------------------------
    // VOICE COMMANDS (EN / ML + LANGUAGE SWITCH)
    // ------------------------------
    function handleVoiceCommand(rawText) {
      const text = rawText.toLowerCase().trim();
      console.log("Voice command:", text);

      // Save + show last command
      lastVoiceCommand = rawText.trim();
      lastVoiceTime = Date.now();

      const display = document.getElementById("voice-command-display");
      display.textContent = `You said: "${lastVoiceCommand}"`;

      const hasAny = (phrases) => phrases.some((p) => text.includes(p));

      if (
        hasAny([
          "malayalam mode",
          "malayalam language",
          "change language to malayalam",
          "‡¥Æ‡¥≤‡¥Ø‡¥æ‡¥≥‡¥Ç ‡¥Æ‡µã‡¥°‡µç",
          "‡¥Æ‡¥≤‡¥Ø‡¥æ‡¥≥‡¥Ç",
        ])
      ) {
        setRecognitionLanguage("ml-IN");
        return;
      }

      if (
        hasAny([
          "english mode",
          "english language",
          "change language to english",
          "‡¥á‡¥Ç‡¥ó‡µç‡¥≤‡µÄ‡¥∑‡µç ‡¥Æ‡µã‡¥°‡µç",
          "‡¥á‡¥Ç‡¥ó‡µç‡¥≤‡µÄ‡¥∑‡µç",
        ])
      ) {
        setRecognitionLanguage("en-IN");
        return;
      }

      if (
        hasAny([
          "object mode",
          "walking mode",
          "‡¥ì‡¥¨‡µç‡¥ú‡¥ï‡µç‡¥ü‡µç ‡¥Æ‡µã‡¥°‡µç",
          "‡¥ì‡¥¨‡µç‚Äå‡¥ú‡¥ï‡µç‡¥±‡µç‡¥±‡µç ‡¥Æ‡µã‡¥°‡µç",
          "‡¥®‡¥ü‡¥ï‡µç‡¥ï‡µΩ ‡¥Æ‡µã‡¥°‡µç",
          "‡¥®‡¥ü‡¥ï‡µç‡¥ï‡¥≤‡µç ‡¥Æ‡µã‡¥°‡µç",
        ])
      ) {
        currentMode = "object";
        updateModeUI();
        setLog("Switched to object mode (walking assistant).");
        speak("Object mode.", { rate: 1.0 });
        if (objectModel && isCameraOn && !isDetecting) {
          isDetecting = true;
          detectLoop();
        }
        return;
      }

      if (
        hasAny([
          "book mode",
          "reading mode",
          "‡¥¨‡µÅ‡¥ï‡µç‡¥ï‡µç ‡¥Æ‡µã‡¥°‡µç",
          "‡¥µ‡¥æ‡¥Ø‡¥® ‡¥Æ‡µã‡¥°‡µç",
          "‡¥µ‡¥æ‡¥Ø‡¥ø‡¥ï‡µç‡¥ï‡¥æ‡¥®‡µÅ‡¥≥‡µç‡¥≥ ‡¥Æ‡µã‡¥°‡µç",
        ])
      ) {
        currentMode = "book";
        updateModeUI();
        setLog("Switched to book mode. Point to text and say 'read'.");
        speak("Book mode.", { rate: 1.0 });
        isDetecting = false;
        ctx && ctx.clearRect(0, 0, canvas.width, canvas.height);
        return;
      }

      if (
        hasAny([
          "mute",
          "stop talking",
          "silent",
          "‡¥Æ‡µç‡¥Ø‡µÇ‡¥ü‡µç‡¥ü‡µç",
          "‡¥∂‡¥¨‡µç‡¥¶‡¥Ç ‡¥ì‡¥´‡µç",
          "‡¥∂‡¥¨‡µç‡¥¶‡¥Ç ‡¥®‡¥ø‡µº‡¥§‡µç‡¥§‡µÅ",
          "‡¥∂‡¥¨‡µç‡¥¶‡¥Ç ‡¥®‡¥ø‡¥∞‡µç‚Äç‡¥§‡µç‡¥§‡µÅ",
        ])
      ) {
        speechEnabled = false;
        window.speechSynthesis.cancel();
        setSpeechBadge();
        setLog("Voice feedback muted.");
        return;
      }

      if (
        hasAny([
          "unmute",
          "talk",
          "speak",
          "voice on",
          "‡¥∂‡¥¨‡µç‡¥¶‡¥Ç ‡¥ì‡µ∫",
          "‡¥µ‡µã‡¥Ø‡µç‡¥∏‡µç ‡¥ì‡µ∫",
          "‡¥∂‡¥¨‡µç‡¥¶‡¥Ç ‡¥§‡µÅ‡¥ü‡¥ô‡µç‡¥ô‡µÇ",
          "‡¥∂‡¥¨‡µç‡¥¶‡¥Ç ‡¥§‡µÅ‡¥ü‡¥ô‡µç‡¥ô‡µÅ",
        ])
      ) {
        speechEnabled = true;
        setSpeechBadge();
        setLog("Voice feedback turned on.");
        speak("Voice feedback is now on.", { rate: 1.0 });
        return;
      }

      if (
        hasAny(["read", "reading", "‡¥±‡µÄ‡¥°‡µç", "‡¥µ‡¥æ‡¥Ø‡¥ø‡¥ï‡µç‡¥ï‡µÅ‡¥ï", "‡¥µ‡¥æ‡¥Ø‡¥ø‡¥ï‡µç‡¥ï‡µÇ", "‡¥µ‡¥æ‡¥Ø‡¥ø‡¥ï‡µç‡¥ï‡µÅ"])
      ) {
        currentMode = "book";
        updateModeUI();
        readCurrentFrameText();
        return;
      }

      if (
        hasAny([
          "stop speaking",
          "stop voice",
          "voice stop",
          "‡¥∂‡¥¨‡µç‡¥¶‡¥Ç ‡¥®‡¥ø‡µº‡¥§‡µç‡¥§‡¥ø",
          "‡¥∂‡¥¨‡µç‡¥¶‡¥Ç ‡¥®‡¥ø‡µº‡¥§‡µç‡¥§‡¥£‡¥Ç",
        ])
      ) {
        window.speechSynthesis.cancel();
        setLog("Stopped speaking current message.");
        return;
      }
    }

    function initVoiceRecognition() {
      const SpeechRecognition =
        window.SpeechRecognition || window.webkitSpeechRecognition;
      if (!SpeechRecognition) {
        console.warn("SpeechRecognition not supported.");
        setLog("Voice commands not supported in this browser.");
        const vDisplay = document.getElementById("voice-command-display");
        vDisplay.textContent = "Voice commands not supported in this browser.";
        return;
      }

      recognition = new SpeechRecognition();
      recognition.lang = recognitionLang;
      recognition.continuous = true;
      recognition.interimResults = false;

      recognition.onstart = () => {
        isRecognitionActive = true;
        console.log("Speech recognition started");
      };

      recognition.onend = () => {
        isRecognitionActive = false;
        console.log("Speech recognition ended");
        // Do not auto-start here blindly; 4-second interval + user tap will restart.
      };

      recognition.onresult = (event) => {
        const last = event.results[event.results.length - 1];
        if (!last.isFinal) return;
        const transcript = last[0].transcript.trim();
        handleVoiceCommand(transcript);
      };

      recognition.onerror = (e) => {
        console.warn("Speech recognition error:", e.error);
        if (e.error === "not-allowed" || e.error === "service-not-allowed") {
          setLog(
            "Microphone permission blocked. Please allow mic access in your browser settings."
          );
          speak("I am not allowed to use your microphone. Please check your browser permissions.");
          const vDisplay = document.getElementById("voice-command-display");
          vDisplay.textContent = "Mic permission blocked. Check browser settings.";
        }
      };
    }

    // ------------------------------
    // 4-SECOND VOICE CHECK LOOP
    // ------------------------------
    function startVoiceCheckLoop() {
      setInterval(() => {
        // 1) Restart recognition if we have it and it's not active
        if (recognition && !isRecognitionActive) {
          try {
            recognition.start();
            console.log("4s check: restarting recognition");
          } catch (e) {
            console.warn("4s check: cannot restart recognition:", e);
          }
        }

        // 2) Update the visible last command text
        const display = document.getElementById("voice-command-display");
        if (!lastVoiceCommand) {
          display.textContent =
            "Listening‚Ä¶ No voice command detected yet. Say 'object mode' or 'read'.";
        } else {
          const secondsAgo = Math.round((Date.now() - lastVoiceTime) / 1000);
          display.textContent = `Last command (${secondsAgo}s ago): "${lastVoiceCommand}"`;
        }
      }, VOICE_CHECK_INTERVAL_MS);
    }

    // ------------------------------
    // INIT
    // ------------------------------
    async function init() {
      setLog("Loading AI models‚Ä¶ please wait.");
      setSpeechBadge();
      updateModeUI();

      if (!window.isSecureContext && location.hostname !== "localhost") {
        setLog(
          "This page is not in a secure context. Please run from <strong>http://localhost</strong> or <strong>HTTPS</strong> (GitHub Pages). Camera and microphone may not work here."
        );
      }

      // Check for speech support message
      if (
        !("webkitSpeechRecognition" in window) &&
        !("SpeechRecognition" in window)
      ) {
        const vDisplay = document.getElementById("voice-command-display");
        vDisplay.textContent =
          "Voice commands not supported. Use Chrome on Android or Desktop.";
      }

      try {
        objectModel = await cocoSsd.load();
        setLog("Object detection ready. Starting camera. Tap once to enable voice.");
        speak(
          "NOVA ready. Camera on. I will describe objects with name, distance in meters, position and size. Tap once, then say object mode for walking, book mode for reading, or say read to read the page. Say Malayalam mode or English mode to change command language.",
          { rate: 0.9 }
        );

        await startCamera();

        // Try auto landscape when init runs (may fail silently)
        await forceLandscape();

        initVoiceRecognition();
        startVoiceCheckLoop();
      } catch (err) {
        console.error(err);
        setLog("Failed to load object detection model.");
        speak("I could not load the detection model.", { rate: 1.0 });
      }
    }

    window.addEventListener("load", init);
  </script>
</body>
</html>
